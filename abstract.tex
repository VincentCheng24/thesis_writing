In this thesis, we present a novel approach to perform 3D pose estimation of vehicles from monocular images intended for autonomous driving scenarios. A robust deep neural network is applied to perform 3D dimension proximity estimation, 2D part localization, and 2D part visibility prediction simultaneously. In the inference phase, these learned features are fed to a pose estimation algorithm to recover the 3D location, 3D orientation, and 3D dimensions of the vehicles with the help of a set of 3D vehicle models. Our approach can perform these six tasks simultaneously in real time and handle highly occluded or truncated vehicles. The experiment results show that our approach achieves state-of-the-art performance on six tasks and outperforms most of monocular methods on the challenging KITTI benchmark.

\textbf{Keywords:} 3D pose estimation, 3D vehicle detection, deep learning, computer vision