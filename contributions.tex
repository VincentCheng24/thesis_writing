\subsection{Contributions}

The first contribution is that our approach can predict not only the 3D bounding box for each vehicle but also the 3D position of each vehicle part, even if these parts are occluded by other objects or truncated by the boundaries of the image. The foundation behind this is that vehicles are rigid objects and their geometric characteristics have a lot in common despite of the vehicle types. Therefore, these shared geometric characteristics serve as the priors which make it reasonable that each vehicle can to be expressed by a 3D artificial model along with a scaling vector. This 3D model is integrated by vehicle parts which are further encoded by characteristic points. Besides, we apply regression rather than detection to search and locate these characteristic points. By doing so, our approach can find all the rest of parts, as long as it ascertains the existence of the vehicle object and some parts. Therefore, even through some parts are invisible to the camera, our approach can still localize them. 

The second contribution is the proposed semi-automatic labelling process which generates additional labels to create a new dataset for our approach.  Deep neural networks are greedy for data. Manual labelling is time-consuming and error-prone, let alone it is infeasible to correctly label the very far vehicles or occluded parts in the image. Therefore, we eliminate the human labor to the extend where only the 3D models need to be labelled manually. Then the process automatically selects the best-matching model and projects this model into the real image to generate labels, \eg visibility and characteristic points.  Besides, this process can be easily generalized to other tasks, as long as they require 2D geometry information in the image coordinate and 3D geometry knowledge in the world coordinate.

The third contribution is the multi-task framework which includes a prediction neural network and a inference block. The network can simultaneously perform vehicle parts localization, visibility characterization, and template proximity prediction at high accuracy level and consequentially, the inference block performs the vehicle dimension estimation,  3D vehicle localization, and rotation recovery. All these tasks can be completed in real time, 0.02s per image, which makes it applicable to directly process the video sequence of the vehicle's front camera.